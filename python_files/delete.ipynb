{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/apoyo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/apoyo/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/apoyo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/apoyo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "-*- coding: utf-8 -*-\n",
    "Creado 30 Agosto 2023\n",
    "@author: Carlos Luis Mora Cañas - Carlos Felipe Cortés Cataño\n",
    "\"\"\"\n",
    "# Importar librerias\n",
    "#Manipulación datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "\n",
    "#Tratamiento texto\n",
    "import re\n",
    "import nltk  # Procesamiento del lenguaje natural\n",
    "nltk.download('averaged_perceptron_tagger') #tagger\n",
    "nltk.download('vader_lexicon') #Lexicon\n",
    "nltk.download('wordnet')  # Categorizacion de las palabras\n",
    "nltk.download('stopwords')  # Quitar palabras comunes\n",
    "import string  # Operaciones de cadenas de caracteres\n",
    "from nltk.corpus import stopwords\n",
    "# pip uninstall vaderSentiment\n",
    "# pip install vader-multi\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer # Analisis de sentimiento\n",
    "from textblob import TextBlob #Traductor ingles para mayor precisión\n",
    "\n",
    "#parametros\n",
    "umbral_reduccion_partesco = 0.03  # percentil 3\n",
    "umbral_reduccion_profesiones = 0.01  # percentil 1\n",
    "umbral_reduccion_gestion = 0.01 #percentil 1\n",
    "dias_analisis_observaciones = 300  # Análsis texto ultimos días\n",
    "\n",
    "#funciones\n",
    "# Función para interpretar el sentimiento\n",
    "def interpretar_sentimiento(row):\n",
    "    if row[\"mean_neg\"] > row[\"mean_pos\"]:\n",
    "        return \"1\"  # Negativo\n",
    "    elif row[\"mean_pos\"] > row[\"mean_neg\"]:\n",
    "        return \"2\"  # Positivo\n",
    "    else:\n",
    "        return \"0\"  # Neutro\n",
    "# Función para generar los nombres de las columnas a partir del índice multi-nivel\n",
    "def generate_column_names(columns):\n",
    "    return [f\"{col[1]}_{col[0]}\" for col in columns]\n",
    "# Función para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    # Poner el texto en minúsculas\n",
    "    texto = texto.lower()\n",
    "    #Quitar simbolos\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    texto = re.sub(r'\\n', '', texto)\n",
    "    # Tokenizar el texto y quitar los signos de puntuación\n",
    "    texto = [word.strip(string.punctuation) for word in texto.split(\" \")]\n",
    "    # Quitar las palabras que contengan números\n",
    "    texto = [word for word in texto if not any(c.isdigit() for c in word)]\n",
    "    # Quitar las stop words\n",
    "    stop = stopwords.words('spanish')\n",
    "    texto = [x for x in texto if x not in stop]\n",
    "    # Quitar los tokens vacíos\n",
    "    texto = [t for t in texto if len(t) > 0]\n",
    "    #Unimos texto\n",
    "    texto = ' '.join(texto)\n",
    "    #Quitamos tildes\n",
    "    texto = texto.replace(\"á\", \"a\")\n",
    "    texto = texto.replace(\"é\", \"e\")\n",
    "    texto = texto.replace(\"í\", \"i\")\n",
    "    texto = texto.replace(\"ó\", \"o\")\n",
    "    texto = texto.replace(\"ú\", \"u\")\n",
    "    return texto\n",
    "\n",
    "\n",
    "# Archivo original, elimina duplicados para repetición codigo y estado actual\n",
    "reporte = pd.read_excel(\n",
    "    \"../data/Consulta_promotora_082023.ods\", engine=\"odf\").sort_values(\"fechaSolicitud\").drop_duplicates(\n",
    "    subset=[\"CodigoPrograma\", \"EstadoActual\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos copia, eliminamos los registros que en la importación crean una nueva columna, o tiene errores y la columna\n",
    "data = reporte.copy().drop(reporte[reporte[\"Unnamed: 21\"].notna()].index).drop(\n",
    "    [\"Unnamed: 21\"], axis=1)\n",
    "data = data.drop(data[~data[\"EstadoActual\"].str.contains(\"-\")].index)\n",
    "#Damos uniformidad a los tipos de valores\n",
    "data[\"idTomador\"] = data[\"Documento_cliente\"].replace(\n",
    "    [\"\", \"C\", \"M\"], np.nan, regex=True)\n",
    "data[\"valorCuota1\"] = data[\"valorCuota_1\"].replace(\n",
    "    [\"\", \"factura\"], np.nan, regex=True).astype(float)\n",
    "data[\"diaPagoCuota\"] = data[\"fechaIdealPago_CuotaCancelada\"].astype(str).str.split(\n",
    "    \"-\", expand=True)[2].str.split(\" \", expand=True)[0].fillna(np.nan).astype(float)\n",
    "#Se cambiaron los nombres y se elimina fecha de Nacimiento porque es redundante con edad\n",
    "data = data.drop([\"fechaIdealPago_CuotaCancelada\",\n",
    "                 \"Documento_cliente\", \"valorCuota_1\", \"fechaNacimiento\"], axis=1)\n",
    "\n",
    "# Elimina registros vacios en tipo de programa necesario según reglas de negocio\n",
    "data = data.drop(data[data[\"TipoPrograma\"].isna()].index)\n",
    "\n",
    "# Elimina todos aquellos que sean empresariales, no hacen parte del estudio, solo familiares\n",
    "data = data[data[\"TipoPrograma\"] != \"Empresarial\"]\n",
    "data = data.drop(\"TipoPrograma\", axis=1)\n",
    "\n",
    "# Imputamos valores del valor de la cuota, dependiendo de las medias de la cuota de inscritos y de mascotas\n",
    "temp = data.groupby([\"#_inscritos_activos\", \"#_mascotas_activas\"]).mean()[\n",
    "    [\"valorCuota1\", \"valorUltimaCuota\"]].reset_index()\n",
    "temp = data[data[\"valorCuota1\"].isna()].drop(\n",
    "    [\"valorCuota1\", \"valorUltimaCuota\"], axis=1).merge(temp, on=[\"#_inscritos_activos\", \"#_mascotas_activas\"])\n",
    "data = data.drop(data[data[\"valorCuota1\"].isna()].index)\n",
    "data = pd.concat([data, temp], axis=0)\n",
    "data = data.reset_index().drop(\"index\", axis=1)\n",
    "data = data.rename(columns={'#_inscritos_activos': \"qPersonas\",\n",
    "                            '#_mascotas_activas': \"qMascotas\"})\n",
    "# División del diccionario longitud y latitud en 2 atributos\n",
    "temp = data[[\"CodigoPrograma\", \"coordenadas\"]].dropna()\n",
    "temp = temp.set_index(\"CodigoPrograma\")\n",
    "temp[\"coordenadas\"] = temp[\"coordenadas\"].apply(\n",
    "    lambda indice: indice.split(',\"pov\":')[0])\n",
    "temp[\"coordenadas\"] = temp[\"coordenadas\"].apply(\n",
    "    lambda indice: indice.replace('{\"pos\":{\"latitud\":', \"\").\n",
    "    replace(\"}\", \"\").replace('\"longitud\":', \"\"))\n",
    "temp = temp[\"coordenadas\"].str.split(\",\", expand=True).rename(\n",
    "    columns={0: \"latitud\", 1: \"longitud\"}).reset_index()\n",
    "data = data.merge(temp, on=\"CodigoPrograma\",\n",
    "                  how=\"left\").drop(\"coordenadas\", axis=1)\n",
    "\n",
    "# Estados\n",
    "# Existen estados que son casos especiales, no hacen parte del estudio\n",
    "estados_especiales = [\"Activo - Pendiente de autorización\",\n",
    "                      \"Activo - Programa con inconsistencia\", \"Activo - Activo para verificación\",\n",
    "                      \"Inactivo - Venta no efectiva\", \"Inactivo - Pendiente primer pago\",\n",
    "                      \"Inactivo - Pendiente de autorización\", 'Inactivo - Programa con inconsistencia severa',\n",
    "                      \"Inactivo - Programa con inconsistencia severa\", \"Inactivo - Alianza Olivos Promollano 2021\"\n",
    "                      'Inactivo - Programa pendiente de activación por empresa', \"Inactivo - Desvinculación de la empresa\",\n",
    "                      \"Inactivo - Trámites para realizar contrato\", \"Inactivo - Programa cedido a Santa Rosa o Alto de occidente\",\n",
    "                      \"Inactivo - Cambio de forma de pago (Alto Occidente_Santa _Rosa)\", \"Inactivo - Alianza Olivos Promollano 2021\",\n",
    "                      \"Inactivo - Equipos\", \"Inactivo - Plenitud 50 pendiente por definir\", \"Activo - Programa pendiente de activación por empresa\",\n",
    "                      \"Inactivo - Cancelado Propietario CHEC\"\n",
    "                      ]\n",
    "\n",
    "data = data.drop(data[data[\"EstadoActual\"].astype(\n",
    "    str).isin(estados_especiales)].index)\n",
    "# Definición y validación estados del programa\n",
    "estados = pd.DataFrame(columns=[\"CodigoPrograma\", \"estado\", \"fecha\"])\n",
    "#Primer inactivo - Fecha de rescindido\n",
    "temp = data[[\"CodigoPrograma\", \"FechaRescindido\", \"EstadoActual\"]].rename(\n",
    "    columns={\"FechaRescindido\": \"fecha\", \"EstadoActual\": \"estado\"})\n",
    "temp = temp.drop(temp[temp[\"fecha\"].isna()].index)\n",
    "estados = pd.concat([estados, temp])\n",
    "#Estados contenidos en el atributo Estados\n",
    "temp = data[[\"CodigoPrograma\", \"Estados\"]].dropna()\n",
    "temp[\"Estados\"] = temp[\"Estados\"].str.replace(\n",
    "    \"[\", \"\", regex=True).str.replace(\"]\", \"\", regex=True)\n",
    "temp = temp.set_index(\"CodigoPrograma\")\n",
    "temp = temp[\"Estados\"].str.split(\"},\", expand=True).stack(\n",
    ").reset_index().drop(\"level_1\", axis=1).set_index(\"CodigoPrograma\")\n",
    "temp = temp[0].str.split(\",\", expand=True)\n",
    "temp[1] = temp[2].where(~temp[2].isna(), temp[1])\n",
    "temp = temp.reset_index().rename(columns={0: \"estado\",\n",
    "                                          1: \"fecha\"}).drop(2, axis=1)\n",
    "temp[\"estado\"] = temp[\"estado\"].str.replace(\n",
    "    '{\"Estado\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "temp[\"fecha\"] = temp[\"fecha\"].str.replace(\n",
    "    '\"fechainicio\":\"', \"\", regex=True).str.replace(\n",
    "    '\"fechacancelacion\":\"', \"\", regex=True).str.replace('\"}', \"\",\n",
    "                                                        regex=True).str.replace('\"', \"\", regex=True).str.replace('T', \" \", regex=True)\n",
    "estados = pd.concat([estados, temp])\n",
    "#Eliminamos nuevamente estados que son especiales pero esta vez de nuestro nuevo dataframe\n",
    "estados = estados.drop(estados[estados[\"estado\"].astype(\n",
    "    str).isin(estados_especiales)].index)\n",
    "#Eliminamos estados duplicados por fecha y estado\n",
    "estados = estados.drop_duplicates(subset=[\"CodigoPrograma\", \"estado\"])\n",
    "# Agrupación motivos\n",
    "estados = pd.concat([estados.drop(\"estado\", axis=1),\n",
    "                     estados[\"estado\"].str.split(\"-\", expand=True, n=1)\n",
    "                     .rename(columns={0: \"estado\", 1: \"motivo\"})], axis=1)\n",
    "remplazo_motivos = {\n",
    "    \"Percepción negativa de la empresa por comentarios de un tercero\": \"Influencia de seres cercanos\",\n",
    "    \"Cambio de programa- inscritos pasan a plan nuevo Aurora\": \"Admin\", \"Terminación y uso del contrato\": \"Admin\",\n",
    "    \"Cambio de lugar de vivienda\": \"Ubicación\", \"Dificultad para ubicarlo\": \"Ubicación\",\n",
    "    \"Se retira por 50% del servicio por atraso\": \"Incumplimiento\", \"Sala de velación\": \"Mala\",\n",
    "    \"Reportado por la CHEC\": \"Incumplimiento\", \"Cliente de Alto Riesgo\": \"Incumplimiento\",\n",
    "    \"Cobertura del servicio\": \"Mala\", \"Cobros indebidos\": \"Mala\", \"Inconformidad en el recaudo\": \"Mala\",\n",
    "    \"Precio del plan\": \"Costo\", \"PENDIENTE DEFINIR RETIRO\": \"Inactivo\", \"No Interesado\": \"Voluntario\",\n",
    "    \"Problemas económicos\": \"Voluntario\", \"Pago extendido y no uso del servicio\": \"Voluntario\",\n",
    "    \"Programa pendiente de activación por empresa\": \"Inactivo\", \"Mejoramiento del estilo de vida\": \"Influencia\", \"Doblemente afiliado en la aurora\": \"Admin\",\n",
    "    \"Parque cementerio\": \"Mala\", \"Parque crematorio\": \"Mala\", \"Experimentación\": \"Admin\"}\n",
    "\n",
    "estados = estados.replace(remplazo_motivos, regex=True)\n",
    "estados[\"motivo\"] = estados[\"motivo\"].str.split(\" \", expand=True)[1]\n",
    "estados[\"concat\"] = estados[\"estado\"].str.cat(estados[\"motivo\"], \"- \").apply(limpiar_texto).replace(\" \", \"\",regex=True)\n",
    "#Los estados activos no aportan a la medición\n",
    "estados = estados.drop(estados[(estados[\"concat\"] == \"activoactivo\")].index)\n",
    "#Añadiendo los conteos al dataframe principal\n",
    "temp = estados.groupby([\"CodigoPrograma\", \"concat\"]).count()[\n",
    "    \"fecha\"].reset_index()\n",
    "temp = pd.pivot(temp, index=[\"CodigoPrograma\"], columns=['concat'])[\n",
    "    \"fecha\"].reset_index().fillna(0)\n",
    "data = data.merge(temp, how=\"left\", on=\"CodigoPrograma\")\n",
    "data[temp.columns] = data[temp.columns].fillna(0)\n",
    "\n",
    "#La fecha de rescindido la usamos para obtener la duración del programa\n",
    "#Si hay fecha de rescidindo usamos esa fecha sino hay valor nulo usamos la ultima fecha reportada en creación en estado\n",
    "ultima_fecha_solicitud = pd.to_datetime(reporte[\"fechaSolicitud\"].dropna(\n",
    ").sort_values().tail(1).values[0])\n",
    "data[\"FechaRescindido\"] = data[\"FechaRescindido\"].fillna(\n",
    "    ultima_fecha_solicitud)\n",
    "#Calculamos duración del programa\n",
    "data[\"duracion\"] = data[\"FechaRescindido\"] - data[\"fechaSolicitud\"]\n",
    "data[\"duracion\"] = data[\"duracion\"].dt.days\n",
    "#Existen 5 casos con valores negativos esto no debe ocurrir se igualan al promedio según cantidad mascotas y personas\n",
    "temp = data.groupby([\"qPersonas\", \"qMascotas\"]).mean()[\n",
    "    \"duracion\"].reset_index()\n",
    "data = data.merge(temp, on=[\"qPersonas\", \"qMascotas\"])\n",
    "data[\"duracion\"] = data[\"duracion_x\"].where(\n",
    "    data[\"duracion_x\"] > 0, data[\"duracion_y\"])\n",
    "data = data.drop([\"duracion_x\", \"duracion_y\"], axis=1)\n",
    "#Extraemos solo si se es activo o inactivo, se recomienda clasificar en más categorías en futuros proyectos\n",
    "data[\"estado\"] = data[\"EstadoActual\"].str.split(\"-\", expand=True)[0]\n",
    "#Eliminamos columnas con información redudante capturada en variables extraidas\n",
    "data = data.drop([\"fechaSolicitud\", \"FechaRescindido\",\n",
    "                 \"EstadoActual\", \"Estados\"], axis=1)\n",
    "# Conteo facturas generadas y promedio de descuentos otorgados\n",
    "temp = data[[\"CodigoPrograma\", \"Cuotas\"]].dropna()\n",
    "temp[\"Cuotas\"] = temp[\"Cuotas\"].str.replace(\n",
    "    \"[\", \"\", regex=True).str.replace(\"]\", \"\", regex=True)\n",
    "temp = temp.set_index(\"CodigoPrograma\")\n",
    "temp = temp[\"Cuotas\"].str.split(\"},\", expand=True).stack(\n",
    ").reset_index().drop(\"level_1\", axis=1).set_index(\"CodigoPrograma\")\n",
    "temp = temp[0].str.split(\",\", expand=True)\n",
    "temp = temp.reset_index().rename(columns={0: \"factura\",\n",
    "                                          1: \"valorSinDescuento\", 2: \"valorcondescuento\",\n",
    "                                          3: \"cuota\", 4: \"cuotaSinDescuento\", 5: \"cuotaConDescuento\",\n",
    "                                          6: \"porcentajeDescuento\", 7: \"valorDescuento\", 8: \"periodoCuota\"})\n",
    "temp[\"factura\"] = temp[\"factura\"].str.replace(\n",
    "    '{\"factura\":', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "temp[\"valorSinDescuento\"] = temp[\"valorSinDescuento\"].str.replace(\n",
    "    '\"valorTotalFacturaSinDescuento\":', \"\", regex=True)\n",
    "temp[\"valorcondescuento\"] = temp[\"valorcondescuento\"].str.replace(\n",
    "    '\"valorTotalFacturaConDescuento\":', \"\", regex=True)\n",
    "temp[\"cuota\"] = temp[\"cuota\"].str.replace(\n",
    "    '\"cuota\":', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "temp[\"cuota\"] = temp[\"cuota\"].str.replace(\n",
    "    '\"cuota\":', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "temp[\"cuotaSinDescuento\"] = temp[\"cuotaSinDescuento\"].str.replace(\n",
    "    '\"valorCuotaSinDescuento\":', \"\", regex=True)\n",
    "temp[\"cuotaConDescuento\"] = temp[\"cuotaConDescuento\"].str.replace(\n",
    "    '\"valorCuotaConDescuento\":', \"\", regex=True)\n",
    "temp[\"porcentajeDescuento\"] = temp[\"porcentajeDescuento\"].str.replace(\n",
    "    '\"porcentajeDescuento\":', \"\", regex=True)\n",
    "temp[\"valorDescuento\"] = temp[\"valorDescuento\"].str.replace(\n",
    "    '\"valorDescuento\":', \"\", regex=True)\n",
    "temp[\"periodoCuota\"] = temp[\"periodoCuota\"].str.replace(\n",
    "    '\"periodoCuota\":', \"\", regex=True).str.replace('\"', \"\", regex=True).str.replace(' ', \"\", regex=True)\n",
    "cuota = temp[\"cuota\"].str.replace(\"Contrato# \", \"\").str.replace(\"Cuota# \", \"\")\\\n",
    "    .str.split(\"-\", expand=True).rename(columns={0: \"contrato\", 1: \"cuota\"})\n",
    "cuotas = pd.concat([temp.drop(\"cuota\", axis=1), cuota], axis=1)\n",
    "\n",
    "temp = cuotas[\"periodoCuota\"].str.replace(\n",
    "    \"\\\\\", \"\", regex=True).str.replace(\n",
    "    \"}\", \"\", regex=True).str.split(\"-\", expand=True)\\\n",
    "    .rename(columns={0: \"periodoInicial\", 1: \"periodoFinal\"})\n",
    "temp[\"periodoInicial\"] = temp[\"periodoInicial\"].apply(\n",
    "    lambda x: datetime.strptime(x, \"%d/%m/%Y\"))\n",
    "temp[\"periodoFinal\"] = temp[\"periodoFinal\"].apply(\n",
    "    lambda x: datetime.strptime(x, \"%d/%m/%Y\"))\n",
    "cuotas = pd.concat([cuotas.drop(\"periodoCuota\", axis=1), temp], axis=1)\n",
    "# Conteo de facturas generadas\n",
    "new_cuotas = cuotas[[\"CodigoPrograma\",\n",
    "                     \"factura\"]].groupby(\"CodigoPrograma\").count().reset_index().rename(columns={\"factura\": \"qFacturas\"})\n",
    "# Promedio descuentos\n",
    "new_cuotas[\"promPercDesc\"] = cuotas[[\"CodigoPrograma\", \"porcentajeDescuento\"]].astype(\"float\")\\\n",
    "    .groupby(\"CodigoPrograma\").mean().reset_index()[\"porcentajeDescuento\"]\n",
    "#Cantidad de descuento otorgados\n",
    "cuotas[\"valorDescuento\"] = cuotas[\"valorDescuento\"].astype(float)\n",
    "new_cuotas[\"qDescOtorgado\"] = cuotas[cuotas[\"valorDescuento\"]\n",
    "                                     > 0].groupby(\"CodigoPrograma\").count().reset_index()[\"valorDescuento\"]\n",
    "    \n",
    "data = data.merge(new_cuotas, on=\"CodigoPrograma\")\n",
    "data[\"qDescOtorgado\"] = data[\"qDescOtorgado\"].fillna(0)\n",
    "#Calculo de incremento cuota\n",
    "data[\"cambioCuota\"] = data[\"valorUltimaCuota\"] - data[\"valorCuota1\"]\n",
    "#Eliminamos variables redundantes\n",
    "data = data.drop([\"Cuotas\", \"valorCuota1\"], axis=1)\n",
    "\n",
    "\n",
    "#Análisis de texto con observaciones\n",
    "temp = data[[\"CodigoPrograma\", \"Observaciones\"]].dropna()\n",
    "temp[\"Observaciones\"] = temp[\"Observaciones\"].str.replace(\n",
    "    \"[\", \"\", regex=True).str.replace(\"]\", \"\", regex=True)\n",
    "temp = temp.set_index(\"CodigoPrograma\")\n",
    "temp = temp[\"Observaciones\"].str.split(\"},\", expand=True).stack(\n",
    ").reset_index().drop(\"level_1\", axis=1).set_index(\"CodigoPrograma\")\n",
    "temp = temp[0].str.split(\",\", expand=True, n=2)\n",
    "temp = temp.reset_index().rename(columns={0: \"fecha\",\n",
    "                                          1: \"empleado\", 2: \"observacion\",\n",
    "                                          })\n",
    "temp[\"fecha\"] = temp[\"fecha\"].str.replace(\n",
    "    '{\"fechaIngreso\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True)\\\n",
    "    .str.replace('\\\\', \"\", regex=True).str.replace(' ', \"\", regex=True)\n",
    "temp[\"fecha\"] = temp[\"fecha\"].apply(lambda x: datetime.strptime(x, \"%d/%m/%Y\"))\n",
    "temp[\"empleado\"] = temp[\"empleado\"].str.replace(\n",
    "    '\"empleado\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "temp[\"observacion\"] = temp[\"observacion\"].str.replace(\n",
    "    '\"observacion\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "#Descartamos observaciones ultimo año posteriores a la ultima solicitud y los atributos empleado-fecha\n",
    "observaciones = temp[temp[\"fecha\"] > ultima_fecha_solicitud -\n",
    "                     dt.timedelta(dias_analisis_observaciones)][[\"CodigoPrograma\", \"observacion\"]]\n",
    "# Gestiones de recaudo\n",
    "temp = data[[\"CodigoPrograma\", \"GestionesRecaudo\"]].dropna()\n",
    "temp[\"GestionesRecaudo\"] = temp[\"GestionesRecaudo\"].str.replace(\n",
    "    \"[\", \"\", regex=True).str.replace(\"]\", \"\", regex=True)\n",
    "temp = temp.set_index(\"CodigoPrograma\")\n",
    "temp = temp[\"GestionesRecaudo\"].str.split(\"},\", expand=True).stack(\n",
    ").reset_index().drop(\"level_1\", axis=1).set_index(\"CodigoPrograma\")\n",
    "temp = temp[0].str.split(\",\", expand=True, n=3)\n",
    "temp = temp.reset_index().rename(columns={0: \"estado\",\n",
    "                                          1: \"fechaenvio\", 2: \"fechaidealpago\",\n",
    "                                          3: \"mensaje\"})\n",
    "temp[\"estado\"] = temp[\"estado\"].str.replace(\n",
    "    '{\"Estado\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "temp[\"fechaenvio\"] = temp[\"fechaenvio\"].str.replace(\n",
    "    '\"FechaEnvio\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True).str.replace('T', \" \", regex=True)\n",
    "temp[\"fechaidealpago\"] = temp[\"fechaidealpago\"].str.replace(\n",
    "    '\"fechaidealpago\":\"', \"\", regex=True).str.replace('\"', \"\", regex=True).str.replace('T', \" \", regex=True)\n",
    "temp[\"mensaje\"] = temp[\"mensaje\"].str.replace(\n",
    "    '\"Mensaje\":', \"\", regex=True).str.replace('\"', \"\", regex=True)\n",
    "gestion = temp[\"estado\"].str.split(\n",
    "    \"-\", expand=True).rename(columns={0: \"estado\", 1: \"comentario\"})\n",
    "temp = temp.drop(\"estado\", axis=1)\n",
    "recaudos = pd.concat([temp, gestion], axis=1)\n",
    "recaudos = recaudos.dropna(\n",
    "    subset=[\"fechaenvio\", \"fechaidealpago\", \"estado\", \"CodigoPrograma\"])\n",
    "recaudos = recaudos.drop(\n",
    "    recaudos[recaudos[\"fechaidealpago\"].str.isalpha()].index)\n",
    "recaudos = recaudos.drop(\n",
    "    recaudos[recaudos[\"fechaidealpago\"].str.contains(\"a\")].index)\n",
    "recaudos = recaudos.drop(\n",
    "    recaudos[recaudos[\"fechaidealpago\"].apply(lambda x: len(x) < 10)].index)\n",
    "recaudos = recaudos.drop(\n",
    "    recaudos[recaudos[\"fechaenvio\"].str.contains(\"a\")].index)\n",
    "recaudos = recaudos.drop(\n",
    "    recaudos[recaudos[\"fechaenvio\"].apply(lambda x: len(x) < 10)].index)\n",
    "recaudos[\"fechaenvio\"] = recaudos[\"fechaenvio\"].apply(lambda x: datetime.strptime(\n",
    "    x[:10], \"%Y-%m-%d\"))\n",
    "recaudos[\"fechaidealpago\"] = recaudos[\"fechaidealpago\"].apply(lambda x: datetime.strptime(\n",
    "    x[:10], \"%Y-%m-%d\"))\n",
    "\n",
    "recaudos[\"gestion\"] = recaudos[\"fechaenvio\"] - recaudos[\"fechaidealpago\"]\n",
    "#Realizamos conteos de recaudos y los añadimos al dataframe\n",
    "umbral = recaudos[\"comentario\"].count()*umbral_reduccion_gestion\n",
    "temp = recaudos[[\"CodigoPrograma\", \"comentario\", \"estado\"]].groupby(\n",
    "    [\"CodigoPrograma\", \"comentario\"]).count().reset_index()\n",
    "\n",
    "#Si no cumplen el Umbral se reemplaza por otro para reducir la cantidad de atributos\n",
    "no_umbral = recaudos.groupby(\"comentario\").count()\n",
    "no_umbral = no_umbral[no_umbral[\"estado\"] < umbral].index\n",
    "temp[\"comentario\"] = temp[\"comentario\"].where(\n",
    "    ~temp[\"comentario\"].isin(no_umbral), \"otros\")\n",
    "temp = temp.drop_duplicates(subset=[\"CodigoPrograma\", \"comentario\"])\n",
    "temp = pd.pivot(temp, index=[\"CodigoPrograma\"], columns=['comentario'])[\n",
    "    \"estado\"].reset_index().drop(\"otros\", axis=1)\n",
    "temp = temp.rename(\n",
    "    columns={\" Gestión de recaudo cambio en cuotas de carpeta de pagos del cliente\": \"gestionCambioCuotas\",\n",
    "             \" Gestión de recaudo exitosa\": \"gestionExitosa\", \" Gestión de recaudo no exitosa\": \"gestionNoExitoso\",\n",
    "             \" Gestión no ejecutada para el día planeado\": \"gestionNoEjecutada\"})\n",
    "data = data.merge(temp, how=\"left\", on=\"CodigoPrograma\")\n",
    "data[temp.columns] = data[temp.columns].fillna(0)\n",
    "data = data.drop([\"GestionesRecaudo\", \"Observaciones\"], axis=1)\n",
    "\"\"\"No se esta obteniendo adecuadamente los días de realización de la gestión\n",
    "debido a que la fecha del envio no se reporta correctamente, se recomienda corregir este atributo\n",
    "para calcular correctamente los días en que se realiza la gestión,\n",
    "así mismo se evidencia que el atributo mensaje solo contiene 5 mensajes en una serie de recaudos\n",
    "se recomienda dejar comentarios o mensajes para hacer análisis de texto también a este atributo\"\"\"\n",
    "#Para futuro análisis de texto, se concatena con observaciones\n",
    "recaudos = recaudos[[\"CodigoPrograma\", \"mensaje\"]]\n",
    "#Análisis de textos en observaciones\n",
    "observaciones[\"observacion\"] = observaciones[\"observacion\"].apply(\n",
    "    limpiar_texto)\n",
    "#########Falla constantemente la API para traducir los textos\n",
    "analizador = SentimentIntensityAnalyzer()\n",
    "temp = observaciones[\"observacion\"].apply(\n",
    "    lambda x: analizador.polarity_scores(x))\n",
    "resultado = pd.concat([observaciones, temp.apply(pd.Series)], axis=1)\n",
    "\n",
    "# Agrupar por nb_words y realizar operaciones de suma y promedio en las columnas neg, neu, pos, compound\n",
    "temp = resultado.groupby(\"CodigoPrograma\").agg({\"neg\": [\"sum\", \"mean\"], \"neu\": [\n",
    "    \"sum\", \"mean\"], \"pos\": [\"sum\", \"mean\"], \"compound\": [\"sum\", \"mean\"]})\n",
    "# Resetear el índice del DataFrame\n",
    "temp = temp.reset_index()\n",
    "temp.columns = generate_column_names(temp.columns)\n",
    "\n",
    "# Aplicar la función al DataFrame y crear una nueva columna \"sentimiento\"\n",
    "temp[\"sentimiento\"] = temp.apply(\n",
    "    interpretar_sentimiento, axis=1)\n",
    "temp[\"CodigoPrograma\"] = temp[\"_CodigoPrograma\"]\n",
    "data = data.merge(temp[[\"CodigoPrograma\", \"sentimiento\"]],\n",
    "                  how=\"left\", on=\"CodigoPrograma\")\n",
    "data[\"sentimiento\"] = data[\"sentimiento\"].fillna(0)\n",
    "\n",
    "\"\"\"El nivel socioeconomico, variable significativa, se extrae de la latitud y longitud, sin embargo,\n",
    "más del 75% de los datos no presentan estos datos, para complementarlos\n",
    "se puede usar la dirección y la localidad de la venta pero se debe pagar\n",
    "por el servicio ArcGis o uno similar, este presupuesto esta fuera del alcance del proyecto,\n",
    "y no obtamos por perder esa cantidad de datos, se procede a eliminar las variables, solo usaremos la localidad\"\"\"\n",
    "data = data.drop([\"Direccion\", \"longitud\", \"latitud\"], axis=1).rename(\n",
    "    columns={\"LocalidadVenta\": \"localidad\"})\n",
    "# Añade datos titulares\n",
    "datos_titulares = pd.read_excel(\n",
    "    \"../data/base_datos_titulares_e_inscritos.xlsx\")\n",
    "prom_edad = datos_titulares[[\"NOMBRE_TOMADOR\", \"EDAD_INSCRITO\"]]\\\n",
    "    .groupby(\"NOMBRE_TOMADOR\").mean(\"EDAD_INSCRITO\").reset_index()\\\n",
    "    .rename(columns={\"NOMBRE_TOMADOR\": \"tomador\", \"EDAD_INSCRITO\": \"prom_edad_insc\"})\n",
    "#Se añade a la base de datos principal y los valores nulos se llenan con al menos la edad del tomador\n",
    "data = data.merge(prom_edad, on=\"tomador\", how=\"left\")\n",
    "data[\"prom_edad_insc\"] = data[\"prom_edad_insc\"].where(\n",
    "    data[\"prom_edad_insc\"].notna(), data[\"edad\"])\n",
    "#Nombre del plan y profesión del tomador\n",
    "nom_plan = datos_titulares[[\"NOMBRE_TOMADOR\", \"PLAN_EXEQUIAL\", \"PROFESION_TOMADOR\"]].drop_duplicates()\\\n",
    "    .rename(columns={\"NOMBRE_TOMADOR\": \"tomador\", \"PLAN_EXEQUIAL\": \"nom_plan\",\n",
    "                     \"PROFESION_TOMADOR\": \"profesion_tomador\"})\n",
    "data = data.merge(nom_plan, on=\"tomador\", how=\"left\")\n",
    "#Llenamos nulos con identificador unico\n",
    "data[\"profesion_tomador\"] = data[\"profesion_tomador\"].fillna(\"No Identificada\")\n",
    "data[\"nom_plan\"] = data[\"nom_plan\"].fillna(\"No Identificada\")\n",
    "#Reduciendo la cantidad de profesiones con limpieza texto\n",
    "datos_titulares[\"PROFESION_INSCRITO\"] = datos_titulares[\"PROFESION_INSCRITO\"].astype(\n",
    "    str).apply(limpiar_texto)\n",
    "datos_titulares[\"PROFESION_INSCRITO\"] = datos_titulares[\"PROFESION_INSCRITO\"].fillna(\n",
    "    \"identificada\").replace(\"\", \"otros\").replace(\"nan\", \"otros\").replace(\"ninguna\", \"otros\")\\\n",
    "    .replace(\"ama casa\", \"hogar\").replace(\"identificada\", \"otros\")\n",
    "#Reduciendo profesiones que no representen el percentil 1 de los datos\n",
    "umbral = datos_titulares[\"SUCURSAL_VENTA\"].count()*umbral_reduccion_profesiones\n",
    "temp = datos_titulares[[\"NOMBRE_TOMADOR\", \"PROFESION_INSCRITO\", \"SUCURSAL_VENTA\"]].groupby(\n",
    "    [\"NOMBRE_TOMADOR\", \"PROFESION_INSCRITO\"]).count().reset_index()\n",
    "#Si no cumplen el Umbral se reemplaza por otro para reducir la cantidad de atributos\n",
    "no_umbral = temp.groupby(\"PROFESION_INSCRITO\").count()\n",
    "no_umbral = no_umbral[no_umbral[\"SUCURSAL_VENTA\"] < umbral].index\n",
    "temp[\"PROFESION_INSCRITO\"] = temp[\"PROFESION_INSCRITO\"].where(\n",
    "    ~temp[\"PROFESION_INSCRITO\"].isin(no_umbral), \"otros\")\n",
    "temp = temp.drop_duplicates(subset=[\"NOMBRE_TOMADOR\", \"PROFESION_INSCRITO\"])\n",
    "temp = pd.pivot(temp, index=[\"NOMBRE_TOMADOR\"], columns=['PROFESION_INSCRITO'])[\n",
    "    \"SUCURSAL_VENTA\"].reset_index().drop(\"otros\", axis=1)\\\n",
    "    .rename(columns={\"NOMBRE_TOMADOR\": \"tomador\", \"PROFESION_INSCRITO\": \"moda_prof_inscritos\"\n",
    "                     })  # otros es categoría que generaliza\n",
    "data = data.merge(temp, on=\"tomador\", how=\"left\")\n",
    "data[temp.columns] = data[temp.columns].fillna(0)\n",
    "#Reduciendo la cantidad de parentescos con limpieza texto\n",
    "datos_titulares[\"PARENTESCO\"] = datos_titulares[\"PARENTESCO\"].astype(\n",
    "    str).apply(limpiar_texto)\n",
    "temp = datos_titulares[[\"NOMBRE_TOMADOR\", \"PROFESION_INSCRITO\", \"SUCURSAL_VENTA\"]].groupby(\n",
    "    [\"NOMBRE_TOMADOR\", \"PROFESION_INSCRITO\"]).count().reset_index()\n",
    "\n",
    "datos_titulares[\"PARENTESCO\"] = datos_titulares[\"PARENTESCO\"].fillna(\n",
    "    \"otros\").replace(\"\", \"otros\")\n",
    "#Reduciendo parentestos\n",
    "temp = datos_titulares[[\"NOMBRE_TOMADOR\", \"PARENTESCO\", \"SUCURSAL_VENTA\"]].groupby(\n",
    "    [\"NOMBRE_TOMADOR\", \"PARENTESCO\"]).count().reset_index()\n",
    "no_umbral = temp.groupby(\"PARENTESCO\").count()\n",
    "umbral = datos_titulares[\"SUCURSAL_VENTA\"].count(\n",
    ")*umbral_reduccion_partesco  # umbral al 3 en este caso\n",
    "no_umbral = no_umbral[no_umbral[\"SUCURSAL_VENTA\"] < umbral].index\n",
    "temp[\"PARENTESCO\"] = temp[\"PARENTESCO\"].where(\n",
    "    ~temp[\"PARENTESCO\"].isin(no_umbral), \"otros\")\n",
    "temp = temp.drop_duplicates(subset=[\"NOMBRE_TOMADOR\", \"PARENTESCO\"])\n",
    "temp = pd.pivot(temp, index=[\"NOMBRE_TOMADOR\"], columns=['PARENTESCO'])[\n",
    "    \"SUCURSAL_VENTA\"].reset_index().drop([\"otros\", \"titular\"], axis=1)\\\n",
    "    .rename(columns={\"NOMBRE_TOMADOR\": \"tomador\", \"PARENTESCO\": \"moda_parentesco_inscritos\"\n",
    "                     })  # otros es categoría que generaliza\n",
    "data = data.merge(temp, on=\"tomador\", how=\"left\")\n",
    "data[temp.columns] = data[temp.columns].fillna(0)\n",
    "data[\"localidad\"] = data[\"localidad\"].apply(limpiar_texto)\n",
    "data[\"profesion_tomador\"] = data[\"profesion_tomador\"].apply(\n",
    "    limpiar_texto).replace(\" \", \"\", regex=True).replace(\"identificada\", \"noIdentificado\", regex=True).replace(\"\", \"noIdentificada\")\n",
    "data[\"nom_plan\"] = data[\"nom_plan\"].apply(\n",
    "    limpiar_texto).replace(\" \", \"\", regex=True).replace(\"identificada\", \"noIdentificado\", regex=True)\n",
    "data = data.rename(columns={\"oficios varios\": \"oficiosVarios\", \"profesion_tomador\": \"profesionTomador\",\n",
    "                            \"nom_plan\": \"nombrePlan\", \"prom_edad_insc\": \"promedioEdadInscritos\"})\n",
    "data[\"codigoPrograma\"] = data[\"CodigoPrograma\"]\n",
    "data = data.drop(\"CodigoPrograma\", \"tomador\", axis=1)#tenemos el id del tomador\n",
    "data = data.set_index(\"codigoPrograma\")\n",
    "data.to_csv(\"../data/outputs/desercion_version_1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
